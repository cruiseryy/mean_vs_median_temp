{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from time import time\n",
    "import pickle\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "import pymannkendall as mk\n",
    "\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Myriad Pro'\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "\n",
    "path_ = '/home/mizu_home/xp53/nas/BEST/TAVG/'\n",
    "pre_ = 'Complete_TAVG_Daily_LatLong1_'\n",
    "\n",
    "from ipcc_colormap import *\n",
    "cmap_prep = ipcc_cmap()\n",
    "cmap_prep.read_rgb_data_from_excel()\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read processed data from pkl file\n",
    "pkl_file = open('NH_winter_temp_anom.pkl', 'rb')\n",
    "# remove the first 90 rows (JFM of 1980) and the last 61 rows (ND of 2020)\n",
    "temp = pickle.load(pkl_file)\n",
    "\n",
    "# recover the original values by adding the climatology\n",
    "with xr.open_dataset(path_ + pre_ + '1980.nc') as ds:\n",
    "    climatology = ds.climatology.values[:,-90:,:]\n",
    "\n",
    "doy_l = [0, 31, 59, 304, 334]\n",
    "doy_r = [31, 59, 90, 334, 365]\n",
    "ll = [0, 31, 59, 90, 120, 151]\n",
    "for yy in range(40):\n",
    "    for mm in range(5):\n",
    "        il, ir = 151*yy + ll[mm], 151*yy + ll[mm+1]\n",
    "        temp[il:ir,:,:] += climatology[doy_l[mm]:doy_r[mm],:,:]\n",
    "\n",
    "temp = temp[90:-61,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_climatology = np.mean(temp, axis=0)\n",
    "temp_mean = np.zeros((39, 90, 360))\n",
    "temp_median = np.zeros((39, 90, 360))\n",
    "for yy in range(39):\n",
    "    left, right = yy*151, (yy+1)*151\n",
    "    tmean = np.mean(temp[left:right, :, :], axis=0)\n",
    "    tmedian = np.median(temp[left:right, :, :], axis=0)\n",
    "    temp_mean[yy, :, :] = tmean\n",
    "    temp_median[yy, :, :] = tmedian\n",
    "\n",
    "mask = 1 - np.isnan(np.mean(temp, axis=0))\n",
    "mask2 = np.loadtxt('mask_1deg.txt')\n",
    "mask = mask * mask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute median and mean trends and p-values\n",
    "\n",
    "xx = np.arange(39)\n",
    "\n",
    "cnt = 0\n",
    "t1 = time() \n",
    "k_mean = []\n",
    "k_median = []\n",
    "climatology_v = []\n",
    "for i in range(90):\n",
    "    for j in range(360):\n",
    "        if not mask[i, j]:\n",
    "            continue\n",
    "\n",
    "        cnt += 1\n",
    "        if cnt % 1000 == 0:\n",
    "            print('Processing ', cnt, ' grids. Time taken so far: ', time() - t1)\n",
    "\n",
    "        lm1 = TheilSenRegressor(random_state=42)\n",
    "        lm1.fit(xx[:,None], temp_mean[:,i,j])\n",
    "        k_mean.append(lm1.coef_[0] * 10)\n",
    "\n",
    "        lm2 = TheilSenRegressor(random_state=42)\n",
    "        lm2.fit(xx[:,None], temp_median[:,i,j])\n",
    "        k_median.append(lm2.coef_[0] * 10)\n",
    "\n",
    "        climatology_v.append(temp_climatology[i, j])\n",
    "\n",
    "k_mean = np.array(k_mean)\n",
    "k_median = np.array(k_median)\n",
    "climatology_v = np.array(climatology_v)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the bins and corresponding labels\n",
    "bins = [-30, -20, -10, 0, 10]\n",
    "# bins = [-30, -25, -20, -15, -10, -5, 0, 5, 10]\n",
    "label_str = ['<=' + str(bins[0])]\n",
    "for i in range(len(bins)-1):\n",
    "    label_str.append('[' + str(bins[i]) + ',' + str(bins[i+1]) + ']')\n",
    "label_str.append('>' + str(bins[-1]))\n",
    "\n",
    "# Digitize climatology_v based on the bins\n",
    "grouped_indices = np.digitize(climatology_v, bins)\n",
    "\n",
    "k_mean_group = {}\n",
    "k_median_group = {}\n",
    "diff_group = {}\n",
    "climatology_group = {}\n",
    "\n",
    "for i in range(len(bins)+1):\n",
    "    k_mean_group[i] = []\n",
    "    k_median_group[i] = []\n",
    "    diff_group[i] = []\n",
    "    climatology_group[i] = []\n",
    "\n",
    "cnt = 0\n",
    "for idx, group_id in enumerate(grouped_indices):\n",
    "    k_mean_group[group_id].append(k_mean[idx])\n",
    "    k_median_group[group_id].append(k_median[idx])\n",
    "    diff_group[group_id].append(k_median[idx] - k_mean[idx])\n",
    "    climatology_group[group_id].append(climatology_v[idx])\n",
    "    if k_median[idx] - k_mean[idx] > 0:\n",
    "        cnt += 1\n",
    "\n",
    "mid_mean = []\n",
    "upp_mean = []\n",
    "low_mean = []\n",
    "for i in range(len(bins)+1):\n",
    "    mid_mean.append(np.median(k_mean_group[i]))\n",
    "    upp_mean.append(np.percentile(k_mean_group[i], 75))\n",
    "    low_mean.append(np.percentile(k_mean_group[i], 25))\n",
    "\n",
    "mid_median = []\n",
    "upp_median = []\n",
    "low_median = []\n",
    "for i in range(len(bins)+1):\n",
    "    mid_median.append(np.median(k_median_group[i]))\n",
    "    upp_median.append(np.percentile(k_median_group[i], 75))\n",
    "    low_median.append(np.percentile(k_median_group[i], 25))\n",
    "\n",
    "mid_diff = []\n",
    "upp_diff = []\n",
    "low_diff = []\n",
    "for i in range(len(bins)+1):\n",
    "    mid_diff.append(np.median(diff_group[i]))\n",
    "    upp_diff.append(np.percentile(diff_group[i], 25))\n",
    "    low_diff.append(np.percentile(diff_group[i], 75))\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(5, 9))\n",
    "ax[0].plot(np.arange(len(bins)+1), mid_mean, label='Mean')\n",
    "ax[0].fill_between(np.arange(len(bins)+1), low_mean, upp_mean, alpha=0.2)\n",
    "ax[0].plot(np.arange(len(bins)+1), mid_median, label='Median')\n",
    "ax[0].fill_between(np.arange(len(bins)+1), low_median, upp_median, alpha=0.2)\n",
    "ax[0].set_xticks(np.arange(len(bins)+1))\n",
    "ax[0].set_xticklabels(label_str)\n",
    "ax[0].tick_params(axis='x', labelrotation=45)\n",
    "ax[0].legend()\n",
    "ax[0].set_ylabel('Trend [째C/decade]')\n",
    "\n",
    "ax[1].plot(np.arange(len(bins)+1), mid_diff, label='Median - Mean')\n",
    "ax[1].fill_between(np.arange(len(bins)+1), low_diff, upp_diff, alpha=0.2)\n",
    "ax[1].axline((0, 0), slope=0, color='black', linestyle='--')\n",
    "ax[1].set_xticks(np.arange(len(bins)+1))\n",
    "ax[1].set_xticklabels(label_str)\n",
    "ax[1].tick_params(axis='x', labelrotation=45)\n",
    "ax[1].legend()\n",
    "ax[1].set_ylabel('Trend Diff [째C/decade]')\n",
    "\n",
    "ax[2].scatter(climatology_v, k_median - k_mean, color='blue', marker='.', s=1)\n",
    "ax[2].axline((0, 0), slope=0, color='black', linestyle='--')\n",
    "ax[2].set_ylabel('Trend Diff [째C/decade]')\n",
    "ax[2].set_xlabel('Climatology [째C]')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('figures/trends_grouped_by_climatology_whole_NH.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 6\n",
    "neg_cnt = sum([x < 0 for x in diff_group[k]])\n",
    "print(neg_cnt / len(diff_group[k]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wrfplot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
