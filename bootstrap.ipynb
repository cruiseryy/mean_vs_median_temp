{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from time import time\n",
    "import pickle\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import TheilSenRegressor, LinearRegression\n",
    "import pymannkendall as mk\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from matplotlib.patches import Patch\n",
    "plt.rcParams['font.family'] = 'Myriad Pro'\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "\n",
    "\n",
    "\n",
    "path_ = '/home/mizu_home/xp53/nas/home/BEST/TAVG/'\n",
    "pre_ = 'Complete_TAVG_Daily_LatLong1_'\n",
    "\n",
    "from ipcc_colormap import *\n",
    "cmap_prep = ipcc_cmap()\n",
    "cmap_prep.read_rgb_data_from_excel()\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i concatenated two chunks of codes here and you may find duplicate variables (t_50 and temp_median)\n",
    "# but im too lazy to clean it up so bear with me\n",
    "# read processed data from pkl file\n",
    "pkl_file = open('NH_winter_temp.pkl', 'rb')\n",
    "# remove the first 90 rows (JFM of 1980) and the last 61 rows (ND of 2020)\n",
    "temp = pickle.load(pkl_file)[90:-61, :, :]\n",
    "climatology = np.mean(temp, axis=0)\n",
    "\n",
    "temp_mean = np.zeros((39, 90, 360))\n",
    "temp_median = np.zeros((39, 90, 360))\n",
    "t_50 = np.zeros((39, 90, 360))\n",
    "t_95 = np.zeros((39, 90, 360))\n",
    "t_5 = np.zeros((39, 90, 360))\n",
    "\n",
    "for yy in range(39):\n",
    "    left, right = yy*151, (yy+1)*151\n",
    "\n",
    "    tmean = np.mean(temp[left:right, :, :], axis=0)\n",
    "    tmedian = np.median(temp[left:right, :, :], axis=0)\n",
    "    temp_mean[yy, :, :] = tmean\n",
    "    temp_median[yy, :, :] = tmedian\n",
    "\n",
    "    t50 = np.percentile(temp[left:right, :, :], 50, axis=0)\n",
    "    t95 = np.percentile(temp[left:right, :, :], 95, axis=0)\n",
    "    t5 = np.percentile(temp[left:right, :, :], 5, axis=0)\n",
    "    t_50[yy, :, :] = t50\n",
    "    t_95[yy, :, :] = t95\n",
    "    t_5[yy, :, :] = t5\n",
    "\n",
    "# mask out nan values in temperatures\n",
    "mask = 1 - np.isnan(np.mean(temp_mean, axis=0))\n",
    "# the 1-deg mask (mask2) is downscaled from the 2-deg from Gottlieb 2024 et al.\n",
    "mask2 = np.loadtxt('mask_1deg.txt')\n",
    "mask = mask * mask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating trends for original data...\n",
      "Starting bootstrap procedure...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 114\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[38;5;66;03m# 95th percentile trend\u001b[39;00m\n\u001b[1;32m    113\u001b[0m             lm95 \u001b[38;5;241m=\u001b[39m TheilSenRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m--> 114\u001b[0m             \u001b[43mlm95\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboot_t95\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m             bootstrap_k95[n,i,j] \u001b[38;5;241m=\u001b[39m lm95\u001b[38;5;241m.\u001b[39mcoef_[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBootstrap sampling completed in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mt_start\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/home/mizu_home/xp53/.conda/envs/wrfplot/lib/python3.8/site-packages/sklearn/linear_model/_theil_sen.py:445\u001b[0m, in \u001b[0;36mTheilSenRegressor.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    440\u001b[0m weights \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)(\n\u001b[1;32m    441\u001b[0m     delayed(_lstsq)(X, y, index_list[job], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept)\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m job \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_jobs)\n\u001b[1;32m    443\u001b[0m )\n\u001b[1;32m    444\u001b[0m weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(weights)\n\u001b[0;32m--> 445\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_, coefs \u001b[38;5;241m=\u001b[39m \u001b[43m_spatial_median\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept:\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_ \u001b[38;5;241m=\u001b[39m coefs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/home/mizu_home/xp53/.conda/envs/wrfplot/lib/python3.8/site-packages/sklearn/linear_model/_theil_sen.py:122\u001b[0m, in \u001b[0;36m_spatial_median\u001b[0;34m(X, max_iter, tol)\u001b[0m\n\u001b[1;32m    119\u001b[0m spatial_median_old \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_iter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iter):\n\u001b[0;32m--> 122\u001b[0m     spatial_median \u001b[38;5;241m=\u001b[39m \u001b[43m_modified_weiszfeld_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspatial_median_old\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum((spatial_median_old \u001b[38;5;241m-\u001b[39m spatial_median) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m<\u001b[39m tol:\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/home/mizu_home/xp53/.conda/envs/wrfplot/lib/python3.8/site-packages/sklearn/linear_model/_theil_sen.py:68\u001b[0m, in \u001b[0;36m_modified_weiszfeld_step\u001b[0;34m(X, x_old)\u001b[0m\n\u001b[1;32m     65\u001b[0m quotient_norm \u001b[38;5;241m=\u001b[39m linalg\u001b[38;5;241m.\u001b[39mnorm(np\u001b[38;5;241m.\u001b[39msum(diff \u001b[38;5;241m/\u001b[39m diff_norm, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m quotient_norm \u001b[38;5;241m>\u001b[39m _EPSILON:  \u001b[38;5;66;03m# to avoid division by zero\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     new_direction \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdiff_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m diff_norm, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     70\u001b[0m     )\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     new_direction \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/home/mizu_home/xp53/.conda/envs/wrfplot/lib/python3.8/site-packages/numpy/core/fromnumeric.py:2296\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2293\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   2294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m-> 2296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2297\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/mizu_home/xp53/.conda/envs/wrfplot/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# temp has shape (5889, 90, 360)\n",
    "# 5889 days = 39 winters x 151 days/winter\n",
    "# Reshape into (39, 151, 90, 360) format\n",
    "temp_reshaped = np.zeros((39, 151, 90, 360))\n",
    "for i in range(39):\n",
    "    temp_reshaped[i] = temp[i*151:(i+1)*151, :, :]\n",
    "\n",
    "# Conducting bootstrapping experiment for statistical significance of trend differences\n",
    "\n",
    "N = 1000  # Number of bootstrap samples\n",
    "\n",
    "# Initialize arrays to store bootstrapped trends\n",
    "bootstrap_k_mean = np.zeros((N, 90, 360))\n",
    "bootstrap_k_median = np.zeros((N, 90, 360))\n",
    "bootstrap_k5 = np.zeros((N, 90, 360))\n",
    "bootstrap_k95 = np.zeros((N, 90, 360))\n",
    "\n",
    "# Initialize arrays for p-values\n",
    "pval_mean_median = np.zeros((90, 360))\n",
    "pval_5th_median = np.zeros((90, 360))\n",
    "pval_95th_median = np.zeros((90, 360))\n",
    "\n",
    "# Calculate trends on original data once\n",
    "orig_k_mean = np.zeros((90, 360))\n",
    "orig_k_median = np.zeros((90, 360))\n",
    "orig_k5 = np.zeros((90, 360))\n",
    "orig_k95 = np.zeros((90, 360))\n",
    "\n",
    "xx = np.arange(39)  # years\n",
    "\n",
    "print(\"Calculating trends for original data...\")\n",
    "for i in range(90):\n",
    "    for j in range(360):\n",
    "        if not mask[i, j]:\n",
    "            continue\n",
    "            \n",
    "        # Mean trend\n",
    "        lm1 = TheilSenRegressor(random_state=42)\n",
    "        lm1.fit(xx[:,None], temp_mean[:,i,j])\n",
    "        orig_k_mean[i,j] = lm1.coef_[0] * 10\n",
    "        \n",
    "        # Median trend\n",
    "        lm2 = TheilSenRegressor(random_state=42)\n",
    "        lm2.fit(xx[:,None], temp_median[:,i,j])\n",
    "        orig_k_median[i,j] = lm2.coef_[0] * 10\n",
    "        \n",
    "        # 5th percentile trend\n",
    "        lm5 = TheilSenRegressor(random_state=42)\n",
    "        lm5.fit(xx[:,None], t_5[:,i,j])\n",
    "        orig_k5[i,j] = lm5.coef_[0] * 10\n",
    "        \n",
    "        # 95th percentile trend\n",
    "        lm95 = TheilSenRegressor(random_state=42)\n",
    "        lm95.fit(xx[:,None], t_95[:,i,j])\n",
    "        orig_k95[i,j] = lm95.coef_[0] * 10\n",
    "\n",
    "# Original differences\n",
    "orig_diff_mean_median = orig_k_mean - orig_k_median\n",
    "orig_diff_5th_median = orig_k5 - orig_k_median\n",
    "orig_diff_95th_median = orig_k95 - orig_k_median\n",
    "\n",
    "print(\"Starting bootstrap procedure...\")\n",
    "t_start = time()\n",
    "\n",
    "# Generate N bootstrap samples\n",
    "for n in range(N):\n",
    "    if (n+1) % 50 == 0:\n",
    "        print(f\"Bootstrap sample {n+1}/{N}, time elapsed: {time() - t_start:.2f}s\")\n",
    "    \n",
    "    # Create bootstrapped dataset by resampling years with replacement\n",
    "    year_indices = np.random.choice(39, size=39, replace=True)\n",
    "    \n",
    "    # Create bootstrapped temperature arrays\n",
    "    boot_temp_mean = np.zeros((39, 90, 360))\n",
    "    boot_temp_median = np.zeros((39, 90, 360))\n",
    "    boot_t5 = np.zeros((39, 90, 360))\n",
    "    boot_t95 = np.zeros((39, 90, 360))\n",
    "    \n",
    "    # For each sampled year, calculate statistics\n",
    "    for i, year_idx in enumerate(year_indices):\n",
    "        # Use the original year's data to preserve seasonality and spatial correlations\n",
    "        boot_temp = temp_reshaped[year_idx]\n",
    "        \n",
    "        # Calculate statistics for this bootstrapped year\n",
    "        boot_temp_mean[i] = np.mean(boot_temp, axis=0)\n",
    "        boot_temp_median[i] = np.median(boot_temp, axis=0)\n",
    "        boot_t5[i] = np.percentile(boot_temp, 5, axis=0)\n",
    "        boot_t95[i] = np.percentile(boot_temp, 95, axis=0)\n",
    "    \n",
    "    # Calculate trends for each grid point\n",
    "    for i in range(90):\n",
    "        for j in range(360):\n",
    "            if not mask[i, j]:\n",
    "                continue\n",
    "            \n",
    "            # Calculate trends using TheilSenRegressor\n",
    "            # Mean trend\n",
    "            lm1 = TheilSenRegressor(random_state=42)\n",
    "            lm1.fit(xx[:,None], boot_temp_mean[:,i,j])\n",
    "            bootstrap_k_mean[n,i,j] = lm1.coef_[0] * 10\n",
    "            \n",
    "            # Median trend\n",
    "            lm2 = TheilSenRegressor(random_state=42)\n",
    "            lm2.fit(xx[:,None], boot_temp_median[:,i,j])\n",
    "            bootstrap_k_median[n,i,j] = lm2.coef_[0] * 10\n",
    "            \n",
    "            # 5th percentile trend\n",
    "            lm5 = TheilSenRegressor(random_state=42)\n",
    "            lm5.fit(xx[:,None], boot_t5[:,i,j])\n",
    "            bootstrap_k5[n,i,j] = lm5.coef_[0] * 10\n",
    "            \n",
    "            # 95th percentile trend\n",
    "            lm95 = TheilSenRegressor(random_state=42)\n",
    "            lm95.fit(xx[:,None], boot_t95[:,i,j])\n",
    "            bootstrap_k95[n,i,j] = lm95.coef_[0] * 10\n",
    "\n",
    "print(f\"Bootstrap sampling completed in {time() - t_start:.2f}s\")\n",
    "\n",
    "# Calculate differences for each bootstrap sample\n",
    "bootstrap_diff_mean_median = bootstrap_k_mean - bootstrap_k_median\n",
    "bootstrap_diff_5th_median = bootstrap_k5 - bootstrap_k_median\n",
    "bootstrap_diff_95th_median = bootstrap_k95 - bootstrap_k_median\n",
    "\n",
    "# Calculate empirical p-values for each grid point\n",
    "print(\"Calculating empirical p-values...\")\n",
    "for i in range(90):\n",
    "    for j in range(360):\n",
    "        if not mask[i, j]:\n",
    "            continue\n",
    "        \n",
    "        # Mean - Median difference\n",
    "        # Two-tailed test: count how many bootstrap samples have abs difference >= abs original difference\n",
    "        abs_diff_orig = np.abs(orig_diff_mean_median[i,j])\n",
    "        abs_diff_boot = np.abs(bootstrap_diff_mean_median[:,i,j])\n",
    "        pval_mean_median[i,j] = np.mean(abs_diff_boot >= abs_diff_orig)\n",
    "        \n",
    "        # 5th percentile - Median difference\n",
    "        abs_diff_orig = np.abs(orig_diff_5th_median[i,j])\n",
    "        abs_diff_boot = np.abs(bootstrap_diff_5th_median[:,i,j])\n",
    "        pval_5th_median[i,j] = np.mean(abs_diff_boot >= abs_diff_orig)\n",
    "        \n",
    "        # 95th percentile - Median difference\n",
    "        abs_diff_orig = np.abs(orig_diff_95th_median[i,j])\n",
    "        abs_diff_boot = np.abs(bootstrap_diff_95th_median[:,i,j])\n",
    "        pval_95th_median[i,j] = np.mean(abs_diff_boot >= abs_diff_orig)\n",
    "\n",
    "print(\"Bootstrapping analysis completed!\")\n",
    "\n",
    "# Save results\n",
    "bootstrap_results = {\n",
    "    'orig_k_mean': orig_k_mean,\n",
    "    'orig_k_median': orig_k_median,\n",
    "    'orig_k5': orig_k5,\n",
    "    'orig_k95': orig_k95,\n",
    "    'orig_diff_mean_median': orig_diff_mean_median,\n",
    "    'orig_diff_5th_median': orig_diff_5th_median,\n",
    "    'orig_diff_95th_median': orig_diff_95th_median,\n",
    "    'pval_mean_median': pval_mean_median,\n",
    "    'pval_5th_median': pval_5th_median,\n",
    "    'pval_95th_median': pval_95th_median\n",
    "}\n",
    "\n",
    "# Optional: save bootstrap results to file\n",
    "with open('bootstrap_results.pkl', 'wb') as f:\n",
    "    pickle.dump(bootstrap_results, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
